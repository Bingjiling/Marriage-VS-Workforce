Y1 = sum(X1*Vh)-c
Y2 = sum(X2*Vh)-c
##Problem 2
#' 1
#' function classify(S,z)
#' @ z the Perceptron weight vector
#' @ S sample data set
#' @ return class label vector y
classify = function(S,z){
a = matrix(z,ncol=1)
sign(S %*% z)
}
#' 2
#' function perceptrain(S,y)
#' returns a list containing z and Z history, where z is again
#' the normal vector zH of the hyperplane
perceptrain = function(S,y){
z = rep(100,ncol(S))
outcome = z
k = 1
while (sum(abs(classify(S,z)-y))!=0){
indicator = abs(classify(S,z)-y)/2
indicator = as.vector(indicator)
gradient = colSums(S*(indicator*(-y)))
z = z - 1/k*gradient
k = k+1
outcome = cbind(z,outcome)
}
return(outcome)
}
#' For 3D vector (-1028,3,92)
#' generate data and train the perceptron
trainData = fakedata(c(-1028,3,92),100)
zMatrix = perceptrain(trainData$S, trainData$y)
classifier = zMatrix[,1]
#' plot the the training data and the trajectory
#' of the algorithm
#' Add color
trainData$color = rep("Black",length(trainData$y))
trainData$color[trainData$y==-1] = "Yellow"
plot(trainData$S[,1],trainData$S[,2],col = trainData$color)
# add the train lines
for(i in 1:ncol(zMatrix)){
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(slope,intercept)
}
#' Generate test data
#' test the classifier
testData = fakedata(c(-1028,3,92),100)
errorRate = sum(classify(testData$S,classifier)-testData$y)/length(testData$y)
# plot the test data and the classifier
testData$color = rep("Black",length(testData$y))
testData$color[testData$y==-1] = "Yellow"
plot(testData$S[,1],testData$S[,2],col = testData$color)
i = 2
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(slope,intercept)
trainData = fakedata(c(-1028,3,92),100)
zMatrix = perceptrain(trainData$S, trainData$y)
classifier = zMatrix[,1]
#Inputs
#w:  w[1:d] is the normal vector of a hyperplane,
#    w[d+1] = -c is the negative offset parameter.
#n: sample size
#Outputs
#S: n by (d+1) sample matrix with last col 1
#y: vector of the associated class labels
fakedata <- function(w, n){
if(! require(MASS))
{
install.packages("MASS")
}
if(! require(mvtnorm))
{
install.packages("mvtnorm")
}
require(MASS)
require(mvtnorm)
# obtain dimension
d <- length(w)-1
# compute the offset vector and a Basis consisting of w and its nullspace
offset <- -w[length(w)] * w[1:d] / sum(w[1:d]^2)
Basis <- cbind(Null(w[1:d]), w[1:d])
# Create samples, correct for offset, and extend
# rmvnorm(n,mean,sigme) ~ generate n samples from N(0,I) distribution
S <- rmvnorm(n, mean=rep(0,d),sigma = diag(1,d)) %*%  t(Basis)
S <- S + matrix(rep(offset,n),n,d,byrow=T)
S <- cbind(S,1)
# compute the class assignments
y <- as.vector(sign(S %*% w))
# add corrective factors to points that lie on the hyperplane.
S[y==0,1:d] <- S[y==0,1:d] + runif(1,-0.5,0.5)*10^(-4)
y = as.vector(sign(S %*% w))
return(list(S=S, y=y))
} # end function fakedata
##Problem 1
Vh = c(1/sqrt(2),1/sqrt(2))
c = 1/(2*sqrt(2))
X1 = c(-3,0)
X2 = c(1/2,1/2)
Y1 = sum(X1*Vh)-c
Y2 = sum(X2*Vh)-c
##Problem 2
#' 1
#' function classify(S,z)
#' @ z the Perceptron weight vector
#' @ S sample data set
#' @ return class label vector y
classify = function(S,z){
a = matrix(z,ncol=1)
sign(S %*% z)
}
#' 2
#' function perceptrain(S,y)
#' returns a list containing z and Z history, where z is again
#' the normal vector zH of the hyperplane
perceptrain = function(S,y){
z = rep(100,ncol(S))
outcome = z
k = 1
while (sum(abs(classify(S,z)-y))!=0){
indicator = abs(classify(S,z)-y)/2
indicator = as.vector(indicator)
gradient = colSums(S*(indicator*(-y)))
z = z - 1/k*gradient
k = k+1
outcome = cbind(z,outcome)
}
return(outcome)
}
#' For 3D vector (-1028,3,92)
#' generate data and train the perceptron
trainData = fakedata(c(-1028,3,92),100)
zMatrix = perceptrain(trainData$S, trainData$y)
classifier = zMatrix[,1]
#' plot the the training data and the trajectory
#' of the algorithm
#' Add color
trainData$color = rep("Black",length(trainData$y))
trainData$color[trainData$y==-1] = "Yellow"
plot(trainData$S[,1],trainData$S[,2],col = trainData$color)
# add the train lines
for(i in 1:ncol(zMatrix)){
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(slope,intercept)
}
#' Generate test data
#' test the classifier
testData = fakedata(c(-1028,3,92),100)
errorRate = sum(classify(testData$S,classifier)-testData$y)/length(testData$y)
# plot the test data and the classifier
testData$color = rep("Black",length(testData$y))
testData$color[testData$y==-1] = "Yellow"
plot(testData$S[,1],testData$S[,2],col = testData$color)
i = 2
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(slope,intercept)
trainData$color = rep("Black",length(trainData$y))
trainData$color[trainData$y==-1] = "Yellow"
plot(trainData$S[,1],trainData$S[,2],col = trainData$color)
zMatrix
i = 1
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(slope,intercept)
plot(1:7,2:8)
abline(-1,3)
abline(1,3)
##Problem 1
Vh = c(1/sqrt(2),1/sqrt(2))
c = 1/(2*sqrt(2))
X1 = c(-3,0)
X2 = c(1/2,1/2)
Y1 = sum(X1*Vh)-c
Y2 = sum(X2*Vh)-c
##Problem 2
#' 1
#' function classify(S,z)
#' @ z the Perceptron weight vector
#' @ S sample data set
#' @ return class label vector y
classify = function(S,z){
a = matrix(z,ncol=1)
sign(S %*% z)
}
#' 2
#' function perceptrain(S,y)
#' returns a list containing z and Z history, where z is again
#' the normal vector zH of the hyperplane
perceptrain = function(S,y){
z = rep(100,ncol(S))
outcome = z
k = 1
while (sum(abs(classify(S,z)-y))!=0){
indicator = abs(classify(S,z)-y)/2
indicator = as.vector(indicator)
gradient = colSums(S*(indicator*(-y)))
z = z - 1/k*gradient
k = k+1
outcome = cbind(z,outcome)
}
return(outcome)
}
#' For 3D vector (-1028,3,92)
#' generate data and train the perceptron
trainData = fakedata(c(-1028,3,92),100)
zMatrix = perceptrain(trainData$S, trainData$y)
classifier = zMatrix[,1]
#' plot the the training data and the trajectory
#' of the algorithm
#' Add color
trainData$color = rep("Black",length(trainData$y))
trainData$color[trainData$y==-1] = "Yellow"
plot(trainData$S[,1],trainData$S[,2],col = trainData$color)
# add the train lines
for(i in 1:ncol(zMatrix)){
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(intercept,slope)
}
#' Generate test data
#' test the classifier
testData = fakedata(c(-1028,3,92),100)
errorRate = sum(classify(testData$S,classifier)-testData$y)/length(testData$y)
# plot the test data and the classifier
testData$color = rep("Black",length(testData$y))
testData$color[testData$y==-1] = "Yellow"
plot(testData$S[,1],testData$S[,2],col = testData$color)
i = 2
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(slope,intercept)
trainData$color = rep("Black",length(trainData$y))
trainData$color[trainData$y==-1] = "Yellow"
plot(trainData$S[,1],trainData$S[,2],col = trainData$color)
i=1
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(intercept,slope)
i=2
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(intercept,slope)
i=1
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(intercept,slope)
i=2
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(intercept,slope)
trainData = fakedata(c(-28,700,92),100)
zMatrix = perceptrain(trainData$S, trainData$y)
classifier = zMatrix[,1]
dim(zMatrix)
trainData = fakedata(c(-28,700,92),100)
zMatrix = perceptrain(trainData$S, trainData$y)
classifier = zMatrix[,1]
#Inputs
#w:  w[1:d] is the normal vector of a hyperplane,
#    w[d+1] = -c is the negative offset parameter.
#n: sample size
#Outputs
#S: n by (d+1) sample matrix with last col 1
#y: vector of the associated class labels
fakedata <- function(w, n){
if(! require(MASS))
{
install.packages("MASS")
}
if(! require(mvtnorm))
{
install.packages("mvtnorm")
}
require(MASS)
require(mvtnorm)
# obtain dimension
d <- length(w)-1
# compute the offset vector and a Basis consisting of w and its nullspace
offset <- -w[length(w)] * w[1:d] / sum(w[1:d]^2)
Basis <- cbind(Null(w[1:d]), w[1:d])
# Create samples, correct for offset, and extend
# rmvnorm(n,mean,sigme) ~ generate n samples from N(0,I) distribution
S <- rmvnorm(n, mean=rep(0,d),sigma = diag(1,d)) %*%  t(Basis)
S <- S + matrix(rep(offset,n),n,d,byrow=T)
S <- cbind(S,1)
# compute the class assignments
y <- as.vector(sign(S %*% w))
# add corrective factors to points that lie on the hyperplane.
S[y==0,1:d] <- S[y==0,1:d] + runif(1,-0.5,0.5)*10^(-4)
y = as.vector(sign(S %*% w))
return(list(S=S, y=y))
} # end function fakedata
trainData = fakedata(c(-28,700,92),100)
zMatrix = perceptrain(trainData$S, trainData$y)
classifier = zMatrix[,1]
dim(zMatrix)
class(zMatrix)
zMatrix
trainData = fakedata(c(-1963,794,8),100)
zMatrix = perceptrain(trainData$S, trainData$y)
classifier = zMatrix[,1]
trainData$color = rep("Black",length(trainData$y))
trainData$color[trainData$y==-1] = "Yellow"
plot(trainData$S[,1],trainData$S[,2],col = trainData$color)
# add the train lines
for(i in 1:ncol(zMatrix)){
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(intercept,slope)
}
testData = fakedata(c(-1963,794,8),100)
errorRate = sum(classify(testData$S,classifier)-testData$y)/length(testData$y)
# plot the test data and the classifier
testData$color = rep("Black",length(testData$y))
testData$color[testData$y==-1] = "Yellow"
plot(testData$S[,1],testData$S[,2],col = testData$color)
i = 1
slope = -zMatrix[1,i]/zMatrix[2,i]
intercept = -zMatrix[3,i]/zMatrix[2,i]
abline(slope,intercept)
errorRate
zMatrix
?plot
## a
x = (0:80)/20
y = exp(-x)
plot(x, y, type = "l", main = "p(x;1)")
x = c(1, 2, 4)
y = exp(-x)
points(x, y, col="yel")
x = c(1, 2, 4)
y = exp(-x)
points(x, y, col="red")
y2 = 2*exp(-2*x)
L1 = prod(y)
L2 = prod(y2)
L1
L2
rm(list = ls())
x = -100:100
y = log(1+exp(x))
plot(x,y)
x = -100:100
y = log(1+exp(-x))
plot(x,y)
y
x = -10:10
y = log(1+exp(-x))
plot(x,y)
x = seq(-10, 10, 0.1)
y = log(1+exp(-x))
plot(x,y)
rm(list=ls())
library("data.table")
install.packages("data.table")
library("data.table")
library("ggplot2")
?save
popDataA = fread("/Users/yutou/Data Science/Data/2013-american-community-survey/pums/ss13pusa.csv", select = colsToKeep)
reRead = 1
if(reRead == 1){
colsToKeep = c("MAR", "ST", "PINCP","SCHL", "ESR")
popDataA = fread("/Users/yutou/Data Science/Data/2013-american-community-survey/pums/ss13pusa.csv", select = colsToKeep)
}
head(popDataA)
#'
#'Read in Dataset
#'@par:
#'colsToKeep : vector of strings / parameters to be kept
#'reRead     : Boolean
#'pathA      : string / path of "ss13pusa.csv"
#'pathB      : string / path of "ss13pusb.csv"
readIn = function(reRead, colsToKeep, pathA, pathB){
if(reRead == TRUE){
popDataA = fread(pathA, select = colsToKeep)
popDataA = fread(pathB, select = colsToKeep)
popData = rbind(popDataA, popDataB)
rm(popDataA, popDataB)
save(popData, file = "popData.RData")
}else{
load("popData.RData")
}
return(popData)
}
rm(list = ls())
#'
#'Read in Dataset
#'@par:
#'colsToKeep : vector of strings / parameters to be kept
#'reRead     : Boolean
#'pathA      : string / path of "ss13pusa.csv"
#'pathB      : string / path of "ss13pusb.csv"
readIn = function(reRead, colsToKeep, pathA, pathB){
if(reRead == TRUE){
popDataA = fread(pathA, select = colsToKeep)
popDataA = fread(pathB, select = colsToKeep)
popData = rbind(popDataA, popDataB)
rm(popDataA, popDataB)
save(popData, file = "popData.RData")
}else{
load("popData.RData")
}
return(popData)
}
rm(list=ls())
install.packages("coin")
library("coin")
class(group)
score = c(68, 77, 82, 85, 53, 64, 71)
group = c("A","A","A","A", "B","B","B")
class(group)
group = as.factor(group)
class(group)
?"independence_test"
score = c(68, 77, 82, 85, 53, 64, 71)
group = c("A","A","A","A", "B","B","B")
group = as.factor(group)
independence_test(score|group)
score = c(68, 77, 82, 85, 53, 64, 71)
group = c("A","A","A","A", "B","B","B")
group = as.factor(group)
f = as.formula(score|group)
independence_test(f)
score = c(68, 77, 82, 85, 53, 64, 71)
group = c("A","A","A","A", "B","B","B")
group = as.factor(group)
independence_test(score~group)
?sample
groupA = c(1.31,1.45,1.12,1.16,1.30,1.50,1.20,1.22,1.42,1.14,1.23,1.59,1.11,1.10,1.53,1.52,1.17,1.49,1.62,1.29)
groupB = c(1.13,1.71,1.39,1.15,1.33,1.00,1.03,1.68,1.76,1.55,1.34,1.47,1.74,1.74,1.19,1.15,1.20,1.59,1.47)
data = c(groupA, groupB)
disMean = vector()
for(i in 1:1000){
sam = sample(length(data),length(groupA))
samA = data[sam]
samB = data[-sam]
dis = mean(samA) - mean(samB)
disMean = c(disMean, dis)
}
head(disMean)
mean(groupA)-mean(groupB)
groupA = c(1.31,1.45,1.12,1.16,1.30,1.50,1.20,1.22,1.42,1.14,1.23,1.59,1.11,1.10,1.53,1.52,1.17,1.49,1.62,1.29)
groupB = c(1.13,1.71,1.39,1.15,1.33,1.00,1.03,1.68,1.76,1.55,1.34,1.47,1.74,1.74,1.19,1.15,1.20,1.59,1.47)
data = c(groupA, groupB)
disMean = vector()
#Generate 1000 samples
set.seed(7)
for(i in 1:1000){
sam = sample(length(data),length(groupA))
samA = data[sam]
samB = data[-sam]
dis = mean(samA) - mean(samB)
disMean = c(disMean, dis)
}
#Put the true mean diff in and see the index to find the p-value
testStatic = mean(groupA)-mean(groupB)
disMean = c(disMean,testStatic)
disMean = sort(disMean)
index = match(testStatistic, disMean)
groupA = c(1.31,1.45,1.12,1.16,1.30,1.50,1.20,1.22,1.42,1.14,1.23,1.59,1.11,1.10,1.53,1.52,1.17,1.49,1.62,1.29)
groupB = c(1.13,1.71,1.39,1.15,1.33,1.00,1.03,1.68,1.76,1.55,1.34,1.47,1.74,1.74,1.19,1.15,1.20,1.59,1.47)
data = c(groupA, groupB)
disMean = vector()
#Generate 1000 samples
set.seed(7)
for(i in 1:1000){
sam = sample(length(data),length(groupA))
samA = data[sam]
samB = data[-sam]
dis = mean(samA) - mean(samB)
disMean = c(disMean, dis)
}
#Put the true mean diff in and see the index to find the p-value
testStatic = mean(groupA)-mean(groupB)
disMean = c(disMean,testStatic)
disMean = sort(disMean)
index = match(testStatic, disMean)
index
pValue = index/1001*2
?hist
?qnorm
qnorm(0.95)
qnorm(0.975)
?qt
??ggplot
library(ggplot2)
?facet_wrap
getwd()
setwd("~/Data Science/Project1/cycle1-7")
library("survey")
library("dplyr")
library("data.table")
library("ggplot2")
library("choroplethr")
library("choroplethrMaps")
install.packages("survey")
install.packages("data.table")
install.packages("data.table")
install.packages("choroplethr")
install.packages("shoroplethrMaps")
library("survey")
library("dplyr")
library("data.table")
library("ggplot2")
library("choroplethr")
library("choroplethrMaps")
install.packages("survey")
